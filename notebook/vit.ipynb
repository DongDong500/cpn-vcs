{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sdi/anaconda3/envs/sdi_CPNKDv5/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devices: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from vit_pytorch import ViT\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "import utils\n",
    "import criterion\n",
    "from datasets.cpn_vit import CPNvit\n",
    "from utils import ext_transforms as et\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "os.environ['CUDA_DEVICE_ORDER'] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "devices = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'devices: {devices}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num class 1024\n",
    "# 32 x 32 / block size 2^4 = 16 > randn crop\n",
    "\n",
    "v = ViT(\n",
    "    image_size = 512,\n",
    "    patch_size = 16,\n",
    "    num_classes = 1024,\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    heads = 16,\n",
    "    mlp_dim = 2048,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1\n",
    ").to(devices)\n",
    "\n",
    "# img = torch.randn(1, 3, 256, 256).to(devices)\n",
    "# preds = v(img) # (1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len [train]: 374\n"
     ]
    }
   ],
   "source": [
    "transform = et.ExtCompose([\n",
    "            et.ExtRandomCrop(size=(512, 512), is_crop=True, pad_if_needed=True),\n",
    "            et.ExtToTensor(),\n",
    "            et.ExtNormalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "            \n",
    "dst = CPNvit(root='/data1/sdi/datasets', datatype='CPN', image_set='train',\n",
    "            transform=transform, is_rgb=True, dver='splits/v5/3')\n",
    "loader = DataLoader(dst, batch_size=8,\n",
    "                        shuffle=True, num_workers=2, drop_last=True)\n",
    "print(f'len [train]: {len(dst)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(v.parameters(), \n",
    "                        lr=0.1, \n",
    "                        weight_decay=5e-4,\n",
    "                        momentum=0.9)\n",
    "scheduler = utils.PolyLR(optimizer, 2000, power=0.9)\n",
    "\n",
    "costfunction = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running correct: 0.0053\n",
      "running correct: 0.0080\n",
      "running correct: 0.0107\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 2000):\n",
    "\n",
    "    v.train()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0.0\n",
    "\n",
    "    for i, (images, labels) in enumerate(loader):\n",
    "        images = images.to(devices)\n",
    "        labels = labels.to(devices)\n",
    "\n",
    "        outputs = v(images)\n",
    "        probs = nn.Softmax(dim=1)(outputs)\n",
    "        preds = torch.max(probs, 1)[1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = costfunction(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        running_correct += torch.sum(preds == labels)\n",
    "\n",
    "    scheduler.step()\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = running_correct.float() / len(loader.dataset)\n",
    "    \n",
    "    print(f'running correct: {epoch_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         Rearrange-1            [-1, 1024, 768]               0\n",
      "            Linear-2           [-1, 1024, 1024]         787,456\n",
      "           Dropout-3           [-1, 1025, 1024]               0\n",
      "         LayerNorm-4           [-1, 1025, 1024]           2,048\n",
      "            Linear-5           [-1, 1025, 3072]       3,145,728\n",
      "           Softmax-6       [-1, 16, 1025, 1025]               0\n",
      "           Dropout-7       [-1, 16, 1025, 1025]               0\n",
      "            Linear-8           [-1, 1025, 1024]       1,049,600\n",
      "           Dropout-9           [-1, 1025, 1024]               0\n",
      "        Attention-10           [-1, 1025, 1024]               0\n",
      "          PreNorm-11           [-1, 1025, 1024]               0\n",
      "        LayerNorm-12           [-1, 1025, 1024]           2,048\n",
      "           Linear-13           [-1, 1025, 2048]       2,099,200\n",
      "             GELU-14           [-1, 1025, 2048]               0\n",
      "          Dropout-15           [-1, 1025, 2048]               0\n",
      "           Linear-16           [-1, 1025, 1024]       2,098,176\n",
      "          Dropout-17           [-1, 1025, 1024]               0\n",
      "      FeedForward-18           [-1, 1025, 1024]               0\n",
      "          PreNorm-19           [-1, 1025, 1024]               0\n",
      "        LayerNorm-20           [-1, 1025, 1024]           2,048\n",
      "           Linear-21           [-1, 1025, 3072]       3,145,728\n",
      "          Softmax-22       [-1, 16, 1025, 1025]               0\n",
      "          Dropout-23       [-1, 16, 1025, 1025]               0\n",
      "           Linear-24           [-1, 1025, 1024]       1,049,600\n",
      "          Dropout-25           [-1, 1025, 1024]               0\n",
      "        Attention-26           [-1, 1025, 1024]               0\n",
      "          PreNorm-27           [-1, 1025, 1024]               0\n",
      "        LayerNorm-28           [-1, 1025, 1024]           2,048\n",
      "           Linear-29           [-1, 1025, 2048]       2,099,200\n",
      "             GELU-30           [-1, 1025, 2048]               0\n",
      "          Dropout-31           [-1, 1025, 2048]               0\n",
      "           Linear-32           [-1, 1025, 1024]       2,098,176\n",
      "          Dropout-33           [-1, 1025, 1024]               0\n",
      "      FeedForward-34           [-1, 1025, 1024]               0\n",
      "          PreNorm-35           [-1, 1025, 1024]               0\n",
      "        LayerNorm-36           [-1, 1025, 1024]           2,048\n",
      "           Linear-37           [-1, 1025, 3072]       3,145,728\n",
      "          Softmax-38       [-1, 16, 1025, 1025]               0\n",
      "          Dropout-39       [-1, 16, 1025, 1025]               0\n",
      "           Linear-40           [-1, 1025, 1024]       1,049,600\n",
      "          Dropout-41           [-1, 1025, 1024]               0\n",
      "        Attention-42           [-1, 1025, 1024]               0\n",
      "          PreNorm-43           [-1, 1025, 1024]               0\n",
      "        LayerNorm-44           [-1, 1025, 1024]           2,048\n",
      "           Linear-45           [-1, 1025, 2048]       2,099,200\n",
      "             GELU-46           [-1, 1025, 2048]               0\n",
      "          Dropout-47           [-1, 1025, 2048]               0\n",
      "           Linear-48           [-1, 1025, 1024]       2,098,176\n",
      "          Dropout-49           [-1, 1025, 1024]               0\n",
      "      FeedForward-50           [-1, 1025, 1024]               0\n",
      "          PreNorm-51           [-1, 1025, 1024]               0\n",
      "        LayerNorm-52           [-1, 1025, 1024]           2,048\n",
      "           Linear-53           [-1, 1025, 3072]       3,145,728\n",
      "          Softmax-54       [-1, 16, 1025, 1025]               0\n",
      "          Dropout-55       [-1, 16, 1025, 1025]               0\n",
      "           Linear-56           [-1, 1025, 1024]       1,049,600\n",
      "          Dropout-57           [-1, 1025, 1024]               0\n",
      "        Attention-58           [-1, 1025, 1024]               0\n",
      "          PreNorm-59           [-1, 1025, 1024]               0\n",
      "        LayerNorm-60           [-1, 1025, 1024]           2,048\n",
      "           Linear-61           [-1, 1025, 2048]       2,099,200\n",
      "             GELU-62           [-1, 1025, 2048]               0\n",
      "          Dropout-63           [-1, 1025, 2048]               0\n",
      "           Linear-64           [-1, 1025, 1024]       2,098,176\n",
      "          Dropout-65           [-1, 1025, 1024]               0\n",
      "      FeedForward-66           [-1, 1025, 1024]               0\n",
      "          PreNorm-67           [-1, 1025, 1024]               0\n",
      "        LayerNorm-68           [-1, 1025, 1024]           2,048\n",
      "           Linear-69           [-1, 1025, 3072]       3,145,728\n",
      "          Softmax-70       [-1, 16, 1025, 1025]               0\n",
      "          Dropout-71       [-1, 16, 1025, 1025]               0\n",
      "           Linear-72           [-1, 1025, 1024]       1,049,600\n",
      "          Dropout-73           [-1, 1025, 1024]               0\n",
      "        Attention-74           [-1, 1025, 1024]               0\n",
      "          PreNorm-75           [-1, 1025, 1024]               0\n",
      "        LayerNorm-76           [-1, 1025, 1024]           2,048\n",
      "           Linear-77           [-1, 1025, 2048]       2,099,200\n",
      "             GELU-78           [-1, 1025, 2048]               0\n",
      "          Dropout-79           [-1, 1025, 2048]               0\n",
      "           Linear-80           [-1, 1025, 1024]       2,098,176\n",
      "          Dropout-81           [-1, 1025, 1024]               0\n",
      "      FeedForward-82           [-1, 1025, 1024]               0\n",
      "          PreNorm-83           [-1, 1025, 1024]               0\n",
      "        LayerNorm-84           [-1, 1025, 1024]           2,048\n",
      "           Linear-85           [-1, 1025, 3072]       3,145,728\n",
      "          Softmax-86       [-1, 16, 1025, 1025]               0\n",
      "          Dropout-87       [-1, 16, 1025, 1025]               0\n",
      "           Linear-88           [-1, 1025, 1024]       1,049,600\n",
      "          Dropout-89           [-1, 1025, 1024]               0\n",
      "        Attention-90           [-1, 1025, 1024]               0\n",
      "          PreNorm-91           [-1, 1025, 1024]               0\n",
      "        LayerNorm-92           [-1, 1025, 1024]           2,048\n",
      "           Linear-93           [-1, 1025, 2048]       2,099,200\n",
      "             GELU-94           [-1, 1025, 2048]               0\n",
      "          Dropout-95           [-1, 1025, 2048]               0\n",
      "           Linear-96           [-1, 1025, 1024]       2,098,176\n",
      "          Dropout-97           [-1, 1025, 1024]               0\n",
      "      FeedForward-98           [-1, 1025, 1024]               0\n",
      "          PreNorm-99           [-1, 1025, 1024]               0\n",
      "     Transformer-100           [-1, 1025, 1024]               0\n",
      "        Identity-101                 [-1, 1024]               0\n",
      "       LayerNorm-102                 [-1, 1024]           2,048\n",
      "          Linear-103                 [-1, 1024]       1,049,600\n",
      "================================================================\n",
      "Total params: 52,219,904\n",
      "Trainable params: 52,219,904\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 2481.93\n",
      "Params size (MB): 199.20\n",
      "Estimated Total Size (MB): 2684.13\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(v, (3, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('sdi_CPNKDv5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f49abb083c1b91ac362dbdd0984c7c201137e65743b64ea184949d3f7864438a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
